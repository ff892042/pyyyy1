import numpy as np
import pandas as pd
from sklearn import joblib
import matplotlib.pyplot as plt
import seaborn as sns




train = pd.read_csv("sales_train.csv")
test = pd.read_csv('test.csv')
shops = pd.read_csv('shops.csv')
items = pd.read_csv('items.csv')
item_categories = pd. read_csv('item_categories.csv')

train.head()

# test.head()

# items.head()

# shops.head()

train = train[train.item_cnt_day<1000]
train = train[train.item_cnt_day>0]#用掉負數
# 價格
train = train[train.item_price>1]
train = train[train.item_price<10000]

train['date']= pd.to_datetime(train['date'], format='%d.%m.%Y')#轉成好看一點

# train.head() 確保沒有負數（-1)

train['date'].head()

data = train.groupby([train['date'].apply(lambda x: x.strftime('%Y-%m')),'item_id','shop_id' ]).sum().reset_index()

data.head()

data = data[['date','item_id','shop_id','item_cnt_day']]

data = data.pivot_table(index=['item_id','shop_id'], columns = 'date', values = 'item_cnt_day', fill_value =0).reset_index()#透視表
data.head()

test.head()
test = pd.merge(test, data, on = ['item_id', 'shop_id'], how = 'left')
# merge

test. fillna(0, inplace = True)  
test.head()

x_train = test.drop(['2015-10','item_id','shop_id'], axis = 1)
y_train = test['2015-10']

x_test = test.drop(['2013-02', 'item_id', 'shop_id'], axis = 1)
#做簡單一點把兩種的列和行都設一樣, 題目規定

# x_train.shape
# y_train.shape
# x_test.shape

from sklearn.model_selection import train_test_split
x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.2, random_state = 10)
train.head()

# from sklearn.linear_model import LinearRegression
# reg=LinearRegression()
# reg.fit(x_train, y_train)
#use model
# predictions= reg.predict(x_train)
# predictions
# x_test
# #evaluate model
from sklearn.metrics import r2_score
# r2_score(x_train,predictions)

# plt.scatter(x_train,predictions,color='blue', alpha=0.3)
#怪怪ㄉ
# ----------------------------------------------
#chatgpt幫忙修改
from sklearn.linear_model import LinearRegression


lr = LinearRegression()
lr.fit(x_train,y_train)
lr_pred = lr.predict(x_valid)
print(f"Linear Regression R-squared: {r2_score(y_valid, lr_pred):.4f}")

from sklearn.ensemble import GradientBoostingRegressor

gbr = GradientBoostingRegressor()
gbr.fit(x_train, y_train)

predictions = gbr.predict(x_valid).clip(0, 20)
score = gbr.score(x_valid, y_valid)

print(f"Score: {score:.4f}")

submission = pd.read_csv('sample_submission.csv')
submission['item_cnt_month'] = predictions
submission.to_csv('sample_submission.csv', index=False)
  

#參考：https://blog.csdn.net/Robin_Pi/article/details/103966287?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-103966287-blog-103999778.235%5Ev29%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-2-103966287-blog-103999778.235%5Ev29%5Epc_relevant_default_base3&utm_relevant_index=3
https://blog.csdn.net/Robin_Pi/article/details/103999778?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-103999778-blog-104002680.235%5Ev29%5Epc_relevant_default_base3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2-103999778-blog-104002680.235%5Ev29%5Epc_relevant_default_base3&utm_relevant_index=5

